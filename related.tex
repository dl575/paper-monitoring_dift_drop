\section{Related Work}
\label{sec:related}

% Monitoring
Many monitoring schemes have been developed for various security, reliability,
debugging, and other capabilities. There exist monitoring schemes for uninitialized
memory check \cite{mondrian-asplos02}, array bounds check
\cite{hardbound-asplos08, clause-ase07}, and dynamic information flow
tracking \cite{dift-asplos04, raksha-isca07, loki-osdi08}.
Memtracker \cite{memtracker-hpca07} uses monitoring to check for various
memory-related bugs and errors.  Control flow verification techniques perform
monitoring to check that program execution follows expected control flows
\cite{schuette-comp87, impres-dac06,
kayaalp-isca12}.  Our monitoring architecture is designed to
be generally applicable to any of these instruction-grained monitoring schemes.
% In particular, our proposed architecture may be especially useful for some of
% these more complex schemes which also have higher overheads.  Similarly,
% although many of these schemes showed low overheads in custom hardware, our
% architecture can be used to reduce the overheads when applying these schemes on
% a multi-core platform.
 
% % Filtering
% FADE \cite{fade-hpca14} presents a general filtering engine in order to reduce
% the overheads of monitoring. It filters out redundant updates and null checks
% by reading metadata values. 
% By extending our dataflow engine for partial monitoring, we are able to also
% filter out null checks as well as null metadata propagations, but we do not
% handle filtering redundant updates.
% In contrast to FADE, our dataflow engine only
% requires reading and writing 2-bit flags rather than the entire metadata. 

% Sampling
Statistical sampling is a method that has been applied to various debugging
techniques in order to reduce their performance overheads. For example, Liblit
et al. sampled program runs of thousands of users in order to find bugs
\cite{liblit-pldi05}. This idea has also been applied to detecting memory
leaks~\cite{chilimbi-asplos04}, dataflow analysis~\cite{greathouse-cgo11}, and dynamic information flow tracking\cite{testudo-micro08} and
other run-time monitoring techniques. 
These sampling-based techniques all limit the debugging capabilities in order
to provide lower performance overheads, similar to our architecture's goals.
% Limited Monitoring
In terms of partial monitoring with adjustable overheads, the Quality Virtual Machine (QVM) is a
modification of the Java Virtual Machine (JVM) that supports run-time
monitoring with controllable overheads \cite{qvm-oopsla08}. Similarly, Huang et
al. created a framework for controlling the overheads of software-based
monitoring \cite{huang-sttt12}. 
Lo et al. \cite{lo-rtas14} developed a hardware architecture to limit
monitoring specifically for hard real-time systems.

Our work presents a general and efficient hardware platform to enable
partial monitoring. The architecture is designed to be applicable to a wide range of monitoring
techniques as well as monitor implementations. By studying various potential
uses of partial monitoring, including sampling for cooperative debugging and
partial protection for low overheads, we have determined important dropping
policy decisions to consider in order to best meet the requirements of the
application.

% However, these approaches are not able to explicitly set an overhead budget, as
% our system is able to do. In addition, with the exception of Testudo that is
% designed for one specific monitor, these
% methods have not considered parallel monitoring. Our techniques for generally
% reducing the overheads of monitoring can also be used to enable these
% low-overhead, multi-user/run debugging techniques.
% \ED{clarify how our approach is different. Is it more general - supporting
% a large class of monitors? Is it different because it is for parallel monitoring?
% If so, what's the significance of the parallel monitors?}

% These projects are targeting a similar problem
% to the one we address in this paper. However, both projects are focused on
% software-based monitoring and thus their mechanisms modify the software
% monitoring framework in order to enable or disable monitoring. 
% Instead, our
% architecture provides a general hardware mechanism to control overheads of
% parallel monitoring architectures, largely transparent to the original monitor. 
% In addition, these works prevented
% false positives by enabling and disabling monitoring using only a source-dropping
% policy. 
%  Their architecture performs unrestricted 
% dropping in order to guarantee strict deadlines. 
% Our system allows either source-only dropping or unrestricted dropping to be performed.
% This allows the designer or user to choose the appropriate policy depending on
% the monitoring scheme which has not been previously explored.
% \ED{Is the use of source vs. unrestricted dropping the only major difference for
% this work? That sounds rather weak.}
